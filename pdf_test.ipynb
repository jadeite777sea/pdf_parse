{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行前命令行启动 sudo docker run --rm -p 8070:8070 grobid/grobid:0.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_pdfs_with_grobid(pdf_dir, grobid_url=\"http://localhost:8070/api/processFulltextDocument\"):\n",
    "    \"\"\"\n",
    "    解析指定文件夹内所有 PDF 文件，返回解析结果列表（每项包含文件名和返回XML文本）\n",
    "    \n",
    "    参数:\n",
    "        pdf_dir (str): PDF 文件夹路径\n",
    "        grobid_url (str): GROBID API 地址（默认是本地端口 8070）\n",
    "    \n",
    "    返回:\n",
    "        List[Dict]: [{'filename': 'xxx.pdf', 'tei': '<TEI>...</TEI>'}, ...]\n",
    "    \"\"\"\n",
    "    result_list = []\n",
    "\n",
    "    for filename in os.listdir(pdf_dir):\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            filepath = os.path.join(pdf_dir, filename)\n",
    "            print(f\"解析中: {filename}\")\n",
    "            try:\n",
    "                with open(filepath, 'rb') as f:\n",
    "                    response = requests.post(\n",
    "                        grobid_url,\n",
    "                        files={'input': (filename, f, 'application/pdf')}\n",
    "                    )\n",
    "                if response.status_code == 200:\n",
    "                    result_list.append({\n",
    "                        \"filename\": filename,\n",
    "                        \"tei\": response.text\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"❌ 解析失败: {filename}, 状态码: {response.status_code}\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ 解析出错: {filename}, 错误: {e}\")\n",
    "    \n",
    "    return result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "解析中: chi24_使用强化学习模拟人类情绪.pdf\n",
      "解析中: chi24_用强化学习方法来进行任务切换.pdf\n",
      "解析中: chi21_通过强化学习调整用户界面.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_folder_path = \"/home/wbh/knowledge/files\"\n",
    "results = parse_pdfs_with_grobid(pdf_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_tei_results(results, output_folder):\n",
    "    \"\"\"\n",
    "    将 results 中的每个 TEI 字符串保存为 .tei.xml 文件。\n",
    "    每个元素应该是 {'filename': ..., 'tei': ...}\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for idx, item in enumerate(results):\n",
    "        tei_xml = item.get(\"tei\", \"\")  # 安全获取\n",
    "        filename = os.path.splitext(os.path.basename(item.get(\"filename\", f\"document_{idx+1}\")))[0]\n",
    "        file_path = os.path.join(output_folder, f\"{filename}.tei.xml\")\n",
    "\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(tei_xml)\n",
    "\n",
    "        print(f\"已保存: {file_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存: ./tei_files/chi24_使用强化学习模拟人类情绪.tei.xml\n",
      "已保存: ./tei_files/chi24_用强化学习方法来进行任务切换.tei.xml\n",
      "已保存: ./tei_files/chi21_通过强化学习调整用户界面.tei.xml\n"
     ]
    }
   ],
   "source": [
    "save_tei_results(results, \"./tei_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup, Tag, NavigableString\n",
    "\n",
    "def extract_nested_sections_with_numbered_citations(tei_xml):\n",
    "    soup = BeautifulSoup(tei_xml, \"lxml-xml\")\n",
    "    section_tree = {}\n",
    "\n",
    "    # 引文原始结构映射：id -> biblStruct\n",
    "    bibl_structs = {b.get(\"xml:id\"): b for b in soup.find_all(\"biblStruct\")}\n",
    "\n",
    "    path_stack = []\n",
    "\n",
    "    for div in soup.find_all(\"div\"):\n",
    "        head = div.find(\"head\")\n",
    "        if not head:\n",
    "            continue\n",
    "\n",
    "        section_title = head.get_text(strip=True)\n",
    "        n = head.get(\"n\", None)\n",
    "        level = len(n.split(\".\")) if n else 1\n",
    "        path_stack = path_stack[:level - 1]\n",
    "        path_stack.append(section_title)\n",
    "\n",
    "        # 进入嵌套结构\n",
    "        current = section_tree\n",
    "        for t in path_stack[:-1]:\n",
    "            current = current.setdefault(t, {\"text\": \"\", \"citations\": [], \"subsections\": {}})[\"subsections\"]\n",
    "\n",
    "        section_text = \"\"\n",
    "        citation_order = []\n",
    "\n",
    "        for p in div.find_all(\"p\"):\n",
    "            new_p = \"\"\n",
    "            pending_refs = []\n",
    "\n",
    "            children = list(p.children)\n",
    "            i = 0\n",
    "            while i < len(children):\n",
    "                node = children[i]\n",
    "\n",
    "                if isinstance(node, NavigableString):\n",
    "                    for ref_id in pending_refs:\n",
    "                        if ref_id not in citation_order and ref_id in bibl_structs:\n",
    "                            citation_order.append(ref_id)\n",
    "                        if ref_id in citation_order:\n",
    "                            ref_number = citation_order.index(ref_id) + 1\n",
    "                            new_p += f\"[{ref_number}]\"\n",
    "                    pending_refs = []\n",
    "\n",
    "                    cleaned = re.sub(r'\\[\\d+(?:,\\s*\\d+)*\\]', '', node)\n",
    "                    new_p += cleaned\n",
    "\n",
    "                elif isinstance(node, Tag) and node.name == \"ref\" and node.get(\"type\") == \"bibr\":\n",
    "                    ref_id = node.get(\"target\", \"\").lstrip(\"#\")\n",
    "                    if ref_id:\n",
    "                        pending_refs.append(ref_id)\n",
    "\n",
    "                else:\n",
    "                    for ref_id in pending_refs:\n",
    "                        if ref_id not in citation_order and ref_id in bibl_structs:\n",
    "                            citation_order.append(ref_id)\n",
    "                        if ref_id in citation_order:\n",
    "                            ref_number = citation_order.index(ref_id) + 1\n",
    "                            new_p += f\"[{ref_number}]\"\n",
    "                    pending_refs = []\n",
    "\n",
    "                    try:\n",
    "                        raw = node.get_text()\n",
    "                        cleaned = re.sub(r'\\[\\d+(?:,\\s*\\d+)*\\]', '', raw)\n",
    "                        new_p += cleaned\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                i += 1\n",
    "\n",
    "            for ref_id in pending_refs:\n",
    "                if ref_id not in citation_order and ref_id in bibl_structs:\n",
    "                    citation_order.append(ref_id)\n",
    "                if ref_id in citation_order:\n",
    "                    ref_number = citation_order.index(ref_id) + 1\n",
    "                    new_p += f\"[{ref_number}]\"\n",
    "            pending_refs = []\n",
    "\n",
    "            section_text += new_p.strip() + \" \"\n",
    "\n",
    "        # 构造结构化引用信息\n",
    "        structured_citations = []\n",
    "        for i, ref_id in enumerate(citation_order):\n",
    "            bibl = bibl_structs.get(ref_id)\n",
    "            if not bibl:\n",
    "                continue\n",
    "            title_tag = bibl.find(\"title\")\n",
    "            title = title_tag.get_text(strip=True) if title_tag else \"Unknown Title\"\n",
    "\n",
    "            authors = bibl.find_all(\"persName\")\n",
    "            author_names = [a.get_text(\" \", strip=True) for a in authors]\n",
    "            author_str = \", \".join(author_names)\n",
    "\n",
    "            date_tag = bibl.find(\"date\")\n",
    "            year = date_tag.get(\"when\", \"\") if date_tag else \"\"\n",
    "\n",
    "            structured_citations.append({\n",
    "                \"id\": f\"[{i+1}]\",\n",
    "                \"text\": title,\n",
    "                \"author\": author_str,\n",
    "                \"year\": year\n",
    "            })\n",
    "\n",
    "        # 填充最终结构\n",
    "        current[path_stack[-1]] = {\n",
    "            \"text\": section_text.strip(),\n",
    "            \"citations\": structured_citations,\n",
    "            \"subsections\": {}\n",
    "        }\n",
    "\n",
    "    return section_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: /home/wbh/knowledge/json_files/chi24_使用强化学习模拟人类情绪.tei.json\n",
      "✅ Saved: /home/wbh/knowledge/json_files/chi24_用强化学习方法来进行任务切换.tei.json\n",
      "✅ Saved: /home/wbh/knowledge/json_files/chi21_通过强化学习调整用户界面.tei.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "tei_folder = \"/home/wbh/knowledge/tei_files\"\n",
    "json_folder = \"/home/wbh/knowledge/json_files\"\n",
    "\n",
    "# 如果 json_files 文件夹不存在就创建它\n",
    "os.makedirs(json_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(tei_folder):\n",
    "    if filename.endswith(\".xml\"):\n",
    "        file_path = os.path.join(tei_folder, filename)\n",
    "\n",
    "        # 读取 TEI XML 内容\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            tei_xml = f.read()\n",
    "\n",
    "        # 提取结构信息\n",
    "        parsed = extract_nested_sections_with_numbered_citations(tei_xml)\n",
    "\n",
    "        # 保存为 JSON，路径换成 json_folder 目录\n",
    "        json_filename = filename.replace(\".xml\", \".json\")\n",
    "        json_path = os.path.join(json_folder, json_filename)\n",
    "\n",
    "        with open(json_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "            json.dump(parsed, f_out, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"✅ Saved: {json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grobid_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
