{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sudo docker run --rm -p 8070:8070 grobid/grobid:0.8.1è¿è¡Œå‰å‘½ä»¤è¡Œå¯åŠ¨ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_pdfs_with_grobid(pdf_dir, grobid_url=\"http://localhost:8070/api/processFulltextDocument\"):\n",
    "    \"\"\"\n",
    "    è§£ææŒ‡å®šæ–‡ä»¶å¤¹å†…æ‰€æœ‰ PDF æ–‡ä»¶ï¼Œè¿”å›è§£æç»“æœåˆ—è¡¨ï¼ˆæ¯é¡¹åŒ…å«æ–‡ä»¶åå’Œè¿”å›XMLæ–‡æœ¬ï¼‰\n",
    "    \n",
    "    å‚æ•°:\n",
    "        pdf_dir (str): PDF æ–‡ä»¶å¤¹è·¯å¾„\n",
    "        grobid_url (str): GROBID API åœ°å€ï¼ˆé»˜è®¤æ˜¯æœ¬åœ°ç«¯å£ 8070ï¼‰\n",
    "    \n",
    "    è¿”å›:\n",
    "        List[Dict]: [{'filename': 'xxx.pdf', 'tei': '<TEI>...</TEI>'}, ...]\n",
    "    \"\"\"\n",
    "    result_list = []\n",
    "\n",
    "    for filename in os.listdir(pdf_dir):\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            filepath = os.path.join(pdf_dir, filename)\n",
    "            print(f\"è§£æä¸­: {filename}\")\n",
    "            try:\n",
    "                with open(filepath, 'rb') as f:\n",
    "                    response = requests.post(\n",
    "                        grobid_url,\n",
    "                        files={'input': (filename, f, 'application/pdf')}\n",
    "                    )\n",
    "                if response.status_code == 200:\n",
    "                    result_list.append({\n",
    "                        \"filename\": filename,\n",
    "                        \"tei\": response.text\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"âŒ è§£æå¤±è´¥: {filename}, çŠ¶æ€ç : {response.status_code}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ è§£æå‡ºé”™: {filename}, é”™è¯¯: {e}\")\n",
    "    \n",
    "    return result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è§£æä¸­: chi24_ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¨¡æ‹Ÿäººç±»æƒ…ç»ª.pdf\n",
      "è§£æä¸­: chi24_ç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•æ¥è¿›è¡Œä»»åŠ¡åˆ‡æ¢.pdf\n",
      "è§£æä¸­: chi21_é€šè¿‡å¼ºåŒ–å­¦ä¹ è°ƒæ•´ç”¨æˆ·ç•Œé¢.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_folder_path = \"/home/wbh/knowledge/files\"\n",
    "results = parse_pdfs_with_grobid(pdf_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_tei_results(results, output_folder):\n",
    "    \"\"\"\n",
    "    å°† results ä¸­çš„æ¯ä¸ª TEI å­—ç¬¦ä¸²ä¿å­˜ä¸º .tei.xml æ–‡ä»¶ã€‚\n",
    "    æ¯ä¸ªå…ƒç´ åº”è¯¥æ˜¯ {'filename': ..., 'tei': ...}\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for idx, item in enumerate(results):\n",
    "        tei_xml = item.get(\"tei\", \"\")  # å®‰å…¨è·å–\n",
    "        filename = os.path.splitext(os.path.basename(item.get(\"filename\", f\"document_{idx+1}\")))[0]\n",
    "        file_path = os.path.join(output_folder, f\"{filename}.tei.xml\")\n",
    "\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(tei_xml)\n",
    "\n",
    "        print(f\"å·²ä¿å­˜: {file_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²ä¿å­˜: ./tei_files/chi24_ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¨¡æ‹Ÿäººç±»æƒ…ç»ª.tei.xml\n",
      "å·²ä¿å­˜: ./tei_files/chi24_ç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•æ¥è¿›è¡Œä»»åŠ¡åˆ‡æ¢.tei.xml\n",
      "å·²ä¿å­˜: ./tei_files/chi21_é€šè¿‡å¼ºåŒ–å­¦ä¹ è°ƒæ•´ç”¨æˆ·ç•Œé¢.tei.xml\n"
     ]
    }
   ],
   "source": [
    "save_tei_results(results, \"./tei_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup, Tag, NavigableString\n",
    "\n",
    "def extract_nested_sections_with_numbered_citations(tei_xml):\n",
    "    soup = BeautifulSoup(tei_xml, \"lxml-xml\")\n",
    "    section_tree = {}\n",
    "\n",
    "    # å¼•æ–‡åŸå§‹ç»“æ„æ˜ å°„ï¼šid -> biblStruct\n",
    "    bibl_structs = {b.get(\"xml:id\"): b for b in soup.find_all(\"biblStruct\")}\n",
    "\n",
    "    path_stack = []\n",
    "\n",
    "    for div in soup.find_all(\"div\"):\n",
    "        head = div.find(\"head\")\n",
    "        if not head:\n",
    "            continue\n",
    "\n",
    "        section_title = head.get_text(strip=True)\n",
    "        n = head.get(\"n\", None)\n",
    "        level = len(n.split(\".\")) if n else 1\n",
    "        path_stack = path_stack[:level - 1]\n",
    "        path_stack.append(section_title)\n",
    "\n",
    "        # è¿›å…¥åµŒå¥—ç»“æ„\n",
    "        current = section_tree\n",
    "        for t in path_stack[:-1]:\n",
    "            current = current.setdefault(t, {\"text\": \"\", \"citations\": [], \"subsections\": {}})[\"subsections\"]\n",
    "\n",
    "        section_text = \"\"\n",
    "        citation_order = []\n",
    "\n",
    "        for p in div.find_all(\"p\"):\n",
    "            new_p = \"\"\n",
    "            pending_refs = []\n",
    "\n",
    "            children = list(p.children)\n",
    "            i = 0\n",
    "            while i < len(children):\n",
    "                node = children[i]\n",
    "\n",
    "                if isinstance(node, NavigableString):\n",
    "                    for ref_id in pending_refs:\n",
    "                        if ref_id not in citation_order and ref_id in bibl_structs:\n",
    "                            citation_order.append(ref_id)\n",
    "                        if ref_id in citation_order:\n",
    "                            ref_number = citation_order.index(ref_id) + 1\n",
    "                            new_p += f\"[{ref_number}]\"\n",
    "                    pending_refs = []\n",
    "\n",
    "                    cleaned = re.sub(r'\\[\\d+(?:,\\s*\\d+)*\\]', '', node)\n",
    "                    new_p += cleaned\n",
    "\n",
    "                elif isinstance(node, Tag) and node.name == \"ref\" and node.get(\"type\") == \"bibr\":\n",
    "                    ref_id = node.get(\"target\", \"\").lstrip(\"#\")\n",
    "                    if ref_id:\n",
    "                        pending_refs.append(ref_id)\n",
    "\n",
    "                else:\n",
    "                    for ref_id in pending_refs:\n",
    "                        if ref_id not in citation_order and ref_id in bibl_structs:\n",
    "                            citation_order.append(ref_id)\n",
    "                        if ref_id in citation_order:\n",
    "                            ref_number = citation_order.index(ref_id) + 1\n",
    "                            new_p += f\"[{ref_number}]\"\n",
    "                    pending_refs = []\n",
    "\n",
    "                    try:\n",
    "                        raw = node.get_text()\n",
    "                        cleaned = re.sub(r'\\[\\d+(?:,\\s*\\d+)*\\]', '', raw)\n",
    "                        new_p += cleaned\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                i += 1\n",
    "\n",
    "            for ref_id in pending_refs:\n",
    "                if ref_id not in citation_order and ref_id in bibl_structs:\n",
    "                    citation_order.append(ref_id)\n",
    "                if ref_id in citation_order:\n",
    "                    ref_number = citation_order.index(ref_id) + 1\n",
    "                    new_p += f\"[{ref_number}]\"\n",
    "            pending_refs = []\n",
    "\n",
    "            section_text += new_p.strip() + \" \"\n",
    "\n",
    "        # æ„é€ ç»“æ„åŒ–å¼•ç”¨ä¿¡æ¯\n",
    "        structured_citations = []\n",
    "        for i, ref_id in enumerate(citation_order):\n",
    "            bibl = bibl_structs.get(ref_id)\n",
    "            if not bibl:\n",
    "                continue\n",
    "            title_tag = bibl.find(\"title\")\n",
    "            title = title_tag.get_text(strip=True) if title_tag else \"Unknown Title\"\n",
    "\n",
    "            authors = bibl.find_all(\"persName\")\n",
    "            author_names = [a.get_text(\" \", strip=True) for a in authors]\n",
    "            author_str = \", \".join(author_names)\n",
    "\n",
    "            date_tag = bibl.find(\"date\")\n",
    "            year = date_tag.get(\"when\", \"\") if date_tag else \"\"\n",
    "\n",
    "            structured_citations.append({\n",
    "                \"id\": f\"[{i+1}]\",\n",
    "                \"text\": title,\n",
    "                \"author\": author_str,\n",
    "                \"year\": year\n",
    "            })\n",
    "\n",
    "        # å¡«å……æœ€ç»ˆç»“æ„\n",
    "        current[path_stack[-1]] = {\n",
    "            \"text\": section_text.strip(),\n",
    "            \"citations\": structured_citations,\n",
    "            \"subsections\": {}\n",
    "        }\n",
    "\n",
    "    return section_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: /home/wbh/knowledge/json_files/chi24_ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¨¡æ‹Ÿäººç±»æƒ…ç»ª.tei.json\n",
      "âœ… Saved: /home/wbh/knowledge/json_files/chi24_ç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•æ¥è¿›è¡Œä»»åŠ¡åˆ‡æ¢.tei.json\n",
      "âœ… Saved: /home/wbh/knowledge/json_files/chi21_é€šè¿‡å¼ºåŒ–å­¦ä¹ è°ƒæ•´ç”¨æˆ·ç•Œé¢.tei.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "tei_folder = \"/home/wbh/knowledge/tei_files\"\n",
    "json_folder = \"/home/wbh/knowledge/json_files\"\n",
    "\n",
    "# å¦‚æœ json_files æ–‡ä»¶å¤¹ä¸å­˜åœ¨å°±åˆ›å»ºå®ƒ\n",
    "os.makedirs(json_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(tei_folder):\n",
    "    if filename.endswith(\".xml\"):\n",
    "        file_path = os.path.join(tei_folder, filename)\n",
    "\n",
    "        # è¯»å– TEI XML å†…å®¹\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            tei_xml = f.read()\n",
    "\n",
    "        # æå–ç»“æ„ä¿¡æ¯\n",
    "        parsed = extract_nested_sections_with_numbered_citations(tei_xml)\n",
    "\n",
    "        # ä¿å­˜ä¸º JSONï¼Œè·¯å¾„æ¢æˆ json_folder ç›®å½•\n",
    "        json_filename = filename.replace(\".xml\", \".json\")\n",
    "        json_path = os.path.join(json_folder, json_filename)\n",
    "\n",
    "        with open(json_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "            json.dump(parsed, f_out, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"âœ… Saved: {json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ æ­£åœ¨å¤„ç†: chi24_ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¨¡æ‹Ÿäººç±»æƒ…ç»ª.pdf ...\n",
      "âŒ å‡ºé”™: chi24_ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¨¡æ‹Ÿäººç±»æƒ…ç»ª.pdf\n",
      "Command '['java', '-Xmx4G', '-jar', 'pdffigures2.jar', '-m', 'output/figures/chi24_ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¨¡æ‹Ÿäººç±»æƒ…ç»ª/chi24_ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¨¡æ‹Ÿäººç±»æƒ…ç»ª-', '-d', 'output/json/chi24_ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¨¡æ‹Ÿäººç±»æƒ…ç»ª', '-e', 'files/chi24_ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¨¡æ‹Ÿäººç±»æƒ…ç»ª.pdf']' returned non-zero exit status 1.\n",
      "ğŸ“„ æ­£åœ¨å¤„ç†: chi24_ç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•æ¥è¿›è¡Œä»»åŠ¡åˆ‡æ¢.pdf ...\n",
      "âŒ å‡ºé”™: chi24_ç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•æ¥è¿›è¡Œä»»åŠ¡åˆ‡æ¢.pdf\n",
      "Command '['java', '-Xmx4G', '-jar', 'pdffigures2.jar', '-m', 'output/figures/chi24_ç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•æ¥è¿›è¡Œä»»åŠ¡åˆ‡æ¢/chi24_ç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•æ¥è¿›è¡Œä»»åŠ¡åˆ‡æ¢-', '-d', 'output/json/chi24_ç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•æ¥è¿›è¡Œä»»åŠ¡åˆ‡æ¢', '-e', 'files/chi24_ç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•æ¥è¿›è¡Œä»»åŠ¡åˆ‡æ¢.pdf']' returned non-zero exit status 1.\n",
      "ğŸ“„ æ­£åœ¨å¤„ç†: chi21_é€šè¿‡å¼ºåŒ–å­¦ä¹ è°ƒæ•´ç”¨æˆ·ç•Œé¢.pdf ...\n",
      "âŒ å‡ºé”™: chi21_é€šè¿‡å¼ºåŒ–å­¦ä¹ è°ƒæ•´ç”¨æˆ·ç•Œé¢.pdf\n",
      "Command '['java', '-Xmx4G', '-jar', 'pdffigures2.jar', '-m', 'output/figures/chi21_é€šè¿‡å¼ºåŒ–å­¦ä¹ è°ƒæ•´ç”¨æˆ·ç•Œé¢/chi21_é€šè¿‡å¼ºåŒ–å­¦ä¹ è°ƒæ•´ç”¨æˆ·ç•Œé¢-', '-d', 'output/json/chi21_é€šè¿‡å¼ºåŒ–å­¦ä¹ è°ƒæ•´ç”¨æˆ·ç•Œé¢', '-e', 'files/chi21_é€šè¿‡å¼ºåŒ–å­¦ä¹ è°ƒæ•´ç”¨æˆ·ç•Œé¢.pdf']' returned non-zero exit status 1.\n",
      "\n",
      "ğŸ‰ æ‰€æœ‰ PDF å¤„ç†å®Œæˆï¼\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: Unable to access jarfile pdffigures2.jar\n",
      "Error: Unable to access jarfile pdffigures2.jar\n",
      "Error: Unable to access jarfile pdffigures2.jar\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# è®¾ç½®è·¯å¾„\n",
    "jar_path = \"pdffigures2/pdffigures2.jar\"\n",
    "pdf_dir = \"files\"\n",
    "output_dir = \"output\"\n",
    "\n",
    "figures_dir = os.path.join(output_dir, \"figures\")\n",
    "json_dir = os.path.join(output_dir, \"json\")\n",
    "\n",
    "# åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "os.makedirs(figures_dir, exist_ok=True)\n",
    "os.makedirs(json_dir, exist_ok=True)\n",
    "\n",
    "# éå†æ‰€æœ‰ PDF\n",
    "for filename in os.listdir(pdf_dir):\n",
    "    if not filename.lower().endswith(\".pdf\"):\n",
    "        continue\n",
    "\n",
    "    pdf_path = os.path.join(pdf_dir, filename)\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "\n",
    "    # prefix åªæ˜¯è·¯å¾„å‰ç¼€ï¼Œä¸æ˜¯æ–‡ä»¶å\n",
    "    figure_prefix = os.path.join(figures_dir, base_name + \"_\")\n",
    "    json_prefix = os.path.join(json_dir, base_name + \"_\")\n",
    "\n",
    "    print(f\"ğŸ“„ æ­£åœ¨å¤„ç†: {filename} ...\")\n",
    "\n",
    "    cmd = [\n",
    "        \"java\", \"-Xmx4G\", \"-jar\", jar_path,\n",
    "        \"-m\", figure_prefix,                   # å›¾ç‰‡æ–‡ä»¶å‰ç¼€\n",
    "        \"-d\", json_prefix,                     # JSON æ–‡ä»¶å‰ç¼€\n",
    "        \"-e\",                                   # å¿½ç•¥é”™è¯¯ï¼Œç»§ç»­æ‰§è¡Œ\n",
    "        pdf_path\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True)\n",
    "        print(f\"âœ… å¤„ç†å®Œæˆ: {filename}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ å‡ºé”™: {filename}\\n{e}\")\n",
    "\n",
    "print(\"\\nğŸ‰ æ‰€æœ‰ PDF å¤„ç†å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grobid_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
