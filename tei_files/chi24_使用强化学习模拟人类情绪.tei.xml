<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Simulating Emotions With an Integrated Computational Model of Appraisal and Reinforcement Learning</title>
				<funder ref="#_sAYPJs2">
					<orgName type="full">Hybrid Intelligence project</orgName>
				</funder>
				<funder ref="#_ewgsSVw">
					<orgName type="full">Academy of Finland</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jiayi</forename><forename type="middle">Eurus</forename><surname>Zhang</surname></persName>
							<email>jiayi.eur.zhang@jyu.</email>
						</author>
						<author>
							<persName><forename type="first">Bernard</forename><surname>Hilpert</surname></persName>
							<email>b.hilpert@liacs.leidenuniv.nl</email>
						</author>
						<author>
							<persName><forename type="first">Jussi</forename><forename type="middle">P P</forename><surname>Jokinen</surname></persName>
							<email>jussi.p.p.jokinen@jyu.</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Cognitive Science</orgName>
								<orgName type="institution">University of Jyväskylä</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Leiden University</orgName>
								<address>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Leiden University</orgName>
								<address>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Cognitive Science</orgName>
								<orgName type="institution">University of Jyväskylä</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Simulating Emotions With an Integrated Computational Model of Appraisal and Reinforcement Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5ECC98A6DF98764950FF968A110D91F4</idno>
					<idno type="DOI">10.1145/3613904.3641908</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-01T12:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Human-centered computing → HCI theory</term>
					<term>concepts and models Emotion Modeling</term>
					<term>Reinforcement Learning</term>
					<term>Appraisal Theory</term>
					<term>Computational Rationality</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Figure <ref type="figure">1</ref>: This paper develops and evaluates a computational model of emotion that is based on temporal diference reinforcement learning and appraisal theory. It predicts emotional responses to events by integrating reward processing and cognitive appraisal. In an illustration of a task carried out by human participants, the user tries to achieve a goal using a computer. Multiple successful attempts at the problem result in a self-evaluated feeling of happiness, which our computational model matches. We model interaction as a decision process, where an evaluation of interactive events results in a value prediction update. The appraisal process of emotion is modeled based on diferent computations that are carried out during this evaluation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Emotions have a signifcant infuence on interpersonal dynamics and outcomes in daily interactions. Similar efects are also present in human-computer interaction (HCI) <ref type="bibr" target="#b2">[3]</ref>, where users exhibit emotions akin to face-to-face interactions <ref type="bibr" target="#b45">[46]</ref>. Consequently, emotions shape perceptions of interactive systems and impact the success of interactions <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13]</ref>. It is therefore a long-standing goal of HCI to understand and predict a user's emotions. This is a challenging problem because while humans have an innate ability to recognize emotions in others, and make inferences and reason about them <ref type="bibr" target="#b37">[38]</ref>, computers lack this capacity. They require an explicit emotion model in order to make sense of and adapt to users' emotions.</p><p>Many attempts to enhance computers' emotion detection focus on analyzing psychophysiological signals stemming from the user's autonomic nervous system <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b33">34]</ref>. However, the challenge of automated emotion detection is difcult due to the interplay between emotions and cognition <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b40">41]</ref>. Cognitive processes are unobservable, limiting machines to interpreting emotions based on observable behavior and physiological changes. Yet, if humans can deduce emotions from minimal observations, why can't machines? This paper posits that discerning user emotions requires a theory bridging cognition and emotions. Models accomplishing this implement psychological theories of human cognitive-emotional processes, aiming to deduce emotions from sparse data using modelinformed biases <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b44">45]</ref>. While several such models have emerged recently, their integration into HCI remains limited.</p><p>The main contribution of our paper is the adaptation of the temporal diference reinforcement learning model of appraisal <ref type="bibr" target="#b53">[54]</ref> to HCI. We assess the model's predictive capabilities in an interactive task, and expand it to capture the dynamic nature of emotions during interactions. The model's key innovation is merging a reward processing mechanism with appraisal theory, using a unifed reinforcement learning (RL) framework. Yet, it hasn't so far been adapted to interactive tasks, nor assessed with any real-life tasks involving human emotions. In this study, our focus is on examining and modeling three emotions: happiness, boredom, and irritation. These were selected due to their frequent occurrence in HCI and their substantial impact on user behavior, engagement, and the overall user experience <ref type="bibr" target="#b24">[25]</ref>. The selected emotions represent a spectrum from positive (happiness), via neutral (boredom), to negative (irritation) <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b25">26]</ref>.</p><p>Figure <ref type="figure">1</ref> illustrates the model at work: 'Lucy' strives to achieve her objectives in an interactive task. Each progressive step elicits positive feedback, leading to positive value estimates. As the task advances, Lucy gains confdence in her goal attainment. When prompted about her emotions after the task, she expresses happiness, but also a hint of boredom due to the task's simplicity. She doesn't feel frustrated. The bar graphs in Figure <ref type="figure">1</ref> display human self-report results from a relatively straightforward, rewarding task alongside the model's predictions. The alignment between the two stems from a computational cognitive emotion model that estimates the user's likely emotions given interactive events during the task. Predictions are made by applying a computationally grounded cognitive model, not by observing physiological signals or learning a model from human responses.</p><p>Existing computational cognitive emotion models fall short in predicting the scenarios we present here, primarily because they do not incorporate a simulation of an autonomous agent capable of evaluating and selecting actions to optimize anticipated outcomes. We foresee multiple applications of this approach. First, afective computing researchers could integrate our work to existing models on physiological signals, improving the accuracy of emotion detection. Second, machines equipped with a model-based understanding of their users' emotions can simulate, in silico, alternative courses of action, deciding on one that is best predicted to achieve the desired emotional outcome <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b42">43]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>Understanding and predicting the user's emotions is a long-standing objective in HCI. To that end, afective computing studies and develops systems designed to recognize, interpret, simulate, and respond to human emotions <ref type="bibr" target="#b50">[51]</ref>. Since the founding of this feld <ref type="bibr" target="#b32">[33]</ref>, the main research lines revolve around the detection and interpretation of afective and social signals from humans <ref type="bibr" target="#b49">[50]</ref>, modeling the diferent facets of human-agent interaction <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b43">44]</ref>, as well as computational simulation of emotion processes based on psychological theories <ref type="bibr" target="#b6">[7]</ref>, especially appraisal theories <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b23">24]</ref>. Afective computing has produced a number of key techniques that use sensors to infer emotional states, often based on either basic emotion <ref type="bibr" target="#b14">[15]</ref> or core afect theories <ref type="bibr" target="#b35">[36]</ref>. In contrast, appraisal theory stands out as a promising foundation for computational cognitive emotion models due to its dedication to explaining emotions within integrated cognitive-afective processes inherent to humans <ref type="bibr" target="#b42">[43]</ref>.</p><p>Cognitive models of appraisal delineate an evaluative process (appraisal) by which specifc situations evoke particular emotional responses, given the subject's goals <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b46">47]</ref>. For instance, the component process model (CPM) proposes a set of sequential cognitive checks, which assess situational stimuli based on characteristics like novelty, intrinsic pleasantness, goal relevance, and coping <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b36">37]</ref>. The CPM predicts that the collective efect of these evaluations results in an emotion-specifc outcome profle. Most commonly occurring profles are called 'modal', and are associated with an emotion word, such as happiness, joy, or anger <ref type="bibr" target="#b39">[40]</ref>. Such appraisal models provide a detailed and empirically verifable account of the cognitive mechanics underpinning the appraisal process and its associated emotion <ref type="bibr" target="#b40">[41]</ref>. Moreover, these models enable their specifcs to be formalized in computationally implementable terms <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b36">37]</ref>, making them suitable for creating machines that understand their users' emotions. While this allows for a clear stepby-step analysis of how a specifc emotion may have been elicited by a given situational stimulus, especially for computational implementations of this model, it only provides a framework for the static, momentary assessment of emotion elicitation, i.e. a specifc moment in time. Yet, most scenarios, especially interactive tasks, encompass an extended temporal context and repeated situational evaluations, underscoring the need for a more continuous account of computational appraisal.</p><p>Reward processing models have been used in afective computing and HCI to estimate and predict user responses, allowing systems to adapt their behaviors <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b52">53]</ref>. At its core, a reward processing modeling seeks to understand decision-making based on anticipated rewards, with the ultimate aim of maximizing these rewards over time <ref type="bibr" target="#b0">[1]</ref>. The operating principle is that positive outcomes reinforce behaviors, encouraging their repetition. Yet, the approach has limitations in modeling emotions: it often oversimplifes motivations by assuming agents act purely for rewards, overlooking aspects such as cognitive processing or behavioral constraints. Furthermore, there is still a considerable gap between a reward-processing model of emotion and a realistic model of human emotions.</p><p>Computational rationality is an approach that has recently been used in modeling a variety of interactive tasks <ref type="bibr" target="#b31">[32]</ref>. It posits that humans can be modeled as agents whose decision-making and behavior are optimal within the bounds imposed by information, computational resources, and expected outcome utility <ref type="bibr" target="#b21">[22]</ref>. This approach has an interesting connection to the reward processing model of emotion: in computational rational modeling, RL is used to derive bounded optimal behavior policies. At the heart of computational rationality in HCI is implementing a simulated user's goals as a reward function <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref>. This facilitates the integration of emotion into computational rationality, thereby implementing emotion as part of an emerging modeling paradigm in HCI.</p><p>However, what stands in the way of implementing a model of user's emotions within computational rationality is the aforementioned gap between reward processing models of emotion and a more realistic understanding of human emotions. It has been recently suggested that appraisal theory is a promising candidate for bridging this gap <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b53">54]</ref>. In many ways, appraisal theory is well suited for modeling emotion within the computational rationality framework, if it is implemented via the reward processing carried out in bounded optimal agents. This is because both appraisal theory and computational rationality embrace the importance of goals in making predictions, and note that it is not merely the events of the environment that shape behavior, but also cognition. In a demonstration of this, a recent model integrates appraisal theory with RL <ref type="bibr" target="#b53">[54]</ref>. While the model is promising, it is limited in being evaluated only with vignettes -textual descriptions -of everyday situations. Our goal with this paper is to review the applicability of this model in interactive tasks, and evaluate and design it further to ft this goal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MODELING</head><p>In this section we review the recent model that formalizes emotional appraisal using RL <ref type="bibr" target="#b53">[54]</ref>, and develop it further. In section 3.1 we outline the foundations of RL; in sections 3.2 and 3.3 we describe the existing model that integrates appraisal into RL; and in section 3.4 we build on this model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Sequential Decision-Making</head><p>The model's interactive episodes are formalized via a Markov decision process (MDP), a mathematical framework for modeling decision-making problems in stochastic environments <ref type="bibr" target="#b47">[48]</ref>. It is a tuple &lt; , , , , &gt;, where denotes the set of states and represents the set of actions that the agent can take. The state transition function (, , ′ ) describes the probability of transitioning from state ∈ to state ′ ∈ when taking action ∈ . The reward function (, , ′ ) defnes the immediate reward an agent receives when transitioning from state to state ′ by performing action . The discount factor discounts future rewards when calculating the value of actions.</p><p>In order to maximize the long-term rewards of a sequential decision-making task described with an MDP, an RL agent interacts with the environment, encoding the state transition probabilities and the reward function. The problem of RL is to derive an optimal policy * , which maps states to action probabilities such that behavior according to it maximizes the expected cumulative reward over time. The value function of a state under a policy , denoted as (), is the expected return when starting in state and following policy thereafter. The function () is the state-value function for policy :</p><formula xml:id="formula_0">() = E [ | = ], for all ∈ ,<label>(1)</label></formula><p>Í ∞ where = =0 represents the expected discounted return, and E denotes the expected value of the policy. The value of performing an action ∈ while in a state ∈ is defned as:</p><formula xml:id="formula_1">(, ) = E [ | = , = ], for all ∈ and ∈ . (2)</formula><p>The agent learns the optimal policy by interacting with the environment, receiving feedback in the form of rewards, and updating its value estimates for state-action pairs. In temporal diference (TD) learning, the value estimates are based on the diference between the expected and the observed value:</p><formula xml:id="formula_2">() ← () + [ ′ + ( ′ ) -()],</formula><p>(3) where is the learning rate. ′ is the reward received after moving to the new state and ( ′ ) is the estimated value for the new state. This operation updates the value () associated with a state as soon as the new state ′ is reached, by computing the diference between predicted and observed values. Combining equations 2 and 3 results in a form of TD learning called Q-learning <ref type="bibr" target="#b47">[48]</ref>, which can be expressed as</p><formula xml:id="formula_3">(, ) ← (, ) + [(, ) + max ( ′ , ′ ) -(, )]. (4) ′</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Appraisal Calculation</head><p>Several appraisals are discussed in the literature, including relevance, implication, coping potential, and normative signifcance <ref type="bibr" target="#b38">[39]</ref>. In the RL appraisal model <ref type="bibr" target="#b53">[54]</ref>, four appraisals were considered: suddenness, goal relevance, conduciveness, and power. This choice was made because these appraisals have distinct representational capacities (regarding real-life episodes), and minimal inter-correlation, and they are suitable for integration into an RL model.</p><p>Suddenness is part of the novelty assessment of an event during appraisal. Specifcally, it quantifes the frequency with which a transition to state ′ occurs after action is taken in a prior state by the agent. Suddenness is denoted by and is defned as:</p><formula xml:id="formula_4">ˆ (, , ′ ) = 1 - Í , (<label>5</label></formula><formula xml:id="formula_5">) ′′ ∈ ˆ (, , ′′ )</formula><p>where ˆ is a world model. It approximates the true transition function , and is learned by the agent during interaction. The intuition of ˆ is that the agent learns to expect certain state-action-state transitions, and therefore encountering such a transition triggers a suddenness appraisal: how expected was this transition?</p><p>Goal relevance checks how relevant an event is, given the agent's current goal. The more goal-relevant an event is, the stronger emotional reactions there will probably be <ref type="bibr" target="#b41">[42]</ref>. Goal relevance is operationalized as the magnitude of the TD error observed during value prediction updates:</p><formula xml:id="formula_6">= (1, |Δ|),<label>(6)</label></formula><p>where</p><formula xml:id="formula_7">Δ(, ) = [(, ) + max ′ ( ′ , ′ ) -(, )] is TD error.</formula><p>Conduciveness appraisal in the CPM evaluates if an event aids the agent's goal attainment. Conducive events generally elicit positive emotions, while obstructive ones invoke negative ones <ref type="bibr" target="#b36">[37]</ref>. In the RL appraisal model, conduciveness is likened to both the direction and magnitude of the discrepancy between expected and actual outcomes. This concept is quantifed by standardizing its values between 0 (highly unconducive) and 1 (very conducive), with 0.5 marking neutral events that meet expectations. The intrinsic conduciveness of an event relies on the agent's cognitive value update, informed by prior expectations and goals. Goal conduciveness is expressed as:</p><formula xml:id="formula_8">= ( (Δ, -1), 1) * 0.5 + 0.5,<label>(7)</label></formula><p>It is worth mentioning that goal relevance and conduciveness in emotional appraisal are not inherently correlative. Events that are goal-relevant may still be unconducive, as observed in negative emotions like despair, irritation, and sadness. Conversely, conducive events can have low goal relevance, exemplifed by scenarios eliciting boredom.</p><p>Power appraisal is part of the more general coping evaluation, asking how much an agent infuences an event's outcome. For instance, an experienced user possesses power due to their knowledge, while a novice lacks this. Power appraisal provides a means to explain why a particular event, such as an error message, might cause widely diferent emotions in diferent users (e.g. confusion or even fear in novice users, and irritation in experienced users). In the model, power refects the agent's ability to discern between benefcial and non-benefcial actions. When the values for various actions difer, the agent is believed to have power. Conversely, identical values or a singular action option denote no power. Power is quantifed as:</p><formula xml:id="formula_9">( |max ′ ( ′ ) -avg(( ′ ))|, if |min ′ ( ′ )| &lt; max ′ ( ′ ), ∝ |min ′ ( ′ ) -avg(( ′ ))|, otherwise.<label>(8)</label></formula><p>This formulation underscores that the essence of the agent's power lies in its ability to identify which actions to pursue and which to avoid. In the simulations below, we standardize the power appraisal by dividing by the highest absolute value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Classifer</head><p>In order to predict modal emotions (emotion words such as 'happiness' or 'irritation') from the computed appraisals, the vector of the four appraisals needs to be classifed. In the model, this classifer is created by connecting modal emotions to particular values or profles of such vectors. These profles are shown in Table <ref type="table" target="#tab_0">1</ref>, which summarizes textual descriptions connecting appraisal profles and modal emotions <ref type="bibr" target="#b38">[39]</ref>. Details of how this was done are reported in <ref type="bibr" target="#b53">[54]</ref>. For this study, we employed simulated data to train and test our classifer. The simulated data were generated by transforming nominal appraisals from Table <ref type="table" target="#tab_0">1</ref> into a range of quantitative values (Table <ref type="table">2</ref>). We used a linear Support Vector Machine (SVM) for classifcation, focusing on the penalty parameter to balance maximizing the margin and minimizing classifcation errors. Our goal was to approximate human performance in the classifer. We We tested 100 SVM classifers with varying values (0.0035 to 0.006) against the simulated data. The classifer's precision closely matched human performance at a value of 0.0049, with a variance of 0.0004. To account for individual diferences, we trained an SVM classifer for each participant, each with a value sampled from a normal distribution (mean = 0.0049, variance = 0.0004), refecting the variance in human precision, thereby ensuring that our model not only matched average human performance but also captured individual variability. Importantly, the parameter was not ftted to minimize the model's prediction error against human emotion ratings, but to the same rating precision level as found in the human data. The goal of this procedure was to bring the variance of our modal emotion predictions more in line with human self-responses: with a value too large, only the most intense emotion would be predicted; by lowering the value, the model predicts also other, less intense emotions. This refects how humans are able to experience various emotions simultaneously. With the classifer, the computational appraisal model is able to predict emotion words from value computations of an RL agent, via the equations for diferent appraisals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Extending The Model for Sequential Emotions</head><p>While the model presented above bridges appraisal theory and a general computational approach to modeling interactive behavior, it lacks in capturing the episodic nature of the interaction, wherein a single episode there are bound to be diferent emotional reactions. For instance, encountering an error multiple times during interaction should not result in multiple 'snapshot' instances of irritation, but rather a continuously growing feeling of irritation.</p><p>In other words, emotions do not appear and disappear, but linger and interact.</p><p>To that end, we augment the model. Initially, in this paper, we implement a simple moving window average, which considers not merely the present state evaluation, but those that precede it.</p><formula xml:id="formula_10">() + ( -1) + ... + ( -) SMA() = ,<label>(9)</label></formula><p>+ 1 where, () is the prediction from the classifcation of a given emotion e at time step t, and n is the length of the window. In this paper, experiment 2, we set = 2, but this number depends on the abstraction level of the simulation. In the future, we also envision a discounting factor, making emotions that occurred further in the past have less impact on the present emotional state. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EVALUATION 4.1 General Method</head><p>Given the goal of this paper -adapting an RL-based appraisal model to predict emotion in interactive tasks -, we focus our evaluation on users within an interactive environment. This approach difers from the vignette-based method used previously in validation. This paper introduces two original studies and assesses the model's predictions based on their outcomes. Our focus is on three common emotions in HCI: happiness, boredom, and irritation <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b25">26]</ref>. Happiness refects the fulfllment of a user's goals or desires, and can lead to increased user engagement. Boredom signifes a lack of stimulation, possibly due to a system's failure to maintain the user's interest.</p><p>Irritation is typically associated with frustrating events that may be due to system errors, poor design, or a failure to meet user expectations. The experimental tasks derive from appraisal theory principles, refecting the targeted emotions' appraisal profles (see Table <ref type="table" target="#tab_0">1</ref>). For example, the happiness task featured low-suddenness, and high goal-conduciveness events, while irritation involved goalobstructive events where participants had some power. Having formalized these appraisals computationally, we implemented identical manipulations in the computational task designs. The frst experiment tests the original single-appraisal model against data collected from real emotional experiences. In the second, we test the idea of averaging emotions over longer sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Materials:</head><p>We constructed six online tasks, three for each experiment. The material was a text paragraph (about 220 words) in the English language sourced from Wikipedia, and the participants had to answer questions about the text. Multiple questions were designed from the same source text. To infuence participants' emotions, we made specifc design alterations. For the happiness task, the questions were meaningful, correct answers resulted in positive feedback, and in the end the participant received a message congratulating them for good performance (Figure <ref type="figure" target="#fig_0">2a</ref>). The boredom task featured a large number of monotonous, simple questions, and intentionally neutral feedback both for an individual task and at the end of the experiment (Figure <ref type="figure" target="#fig_0">2b</ref>). Finally, the irritation task incorporated multiple system errors, leading to incorrect selections irrespective of user decisions, culminating in task failure and negative feedback (Figure <ref type="figure" target="#fig_0">2c</ref>). The text and all questions are presented in full in Appendix B. second experiment, = 45 participants were recruited, 15 for each task (average age 29 ( = 7.3), 15 men and 30 women). All participants were sourced online through Prolifc, and were required to be native English speakers.With this requirement we aimed to eliminate potential biases or variations in the comprehension of the text, allowing participants to concentrate primarily on the test's structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Procedure:</head><p>Participants evaluated their emotions using a rating scale that was part of the online experiment design. This scale encompassed emotion words, asking participants to report on their current feelings (0 indicating "not experiencing this emotion at all" and 10 denoting "experiencing this emotion intensely"). Besides the primary emotions of interest (happiness, boredom, irritation), we introduced two other emotions (joy, sadness) to divert concentrated attention from the manipulated emotions. In the frst experiment, the self-report was administered once post-task. In the second, evaluations occurred four times: initially, twice during the tasks, and upon completion. Correlations between the self-reported emotions are reported in the Appendix C. A between-subjects design was used, with participants engaging solely in one of the three emotional conditions. Diferent participants took part in the two experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">Data Analysis:</head><p>In analyzing the self-reporting of the targeted three emotions, we frst standardized them to reduce the impact of individuals interpreting the scale diferently. For each participant, we normalized their ratings by dividing their rating for an emotion by the total sum of their ratings for all three emotions. This ensured that the rating for each emotion ranged between 0 and 1, with the combined ratings always summing up to 1. The rationale for this was that we expected the participants to hold a diferent internal standard for how strong a particular rating for an emotion is. However, what could be assumed to be common to all participants is how they rate the emotions in relation to each other.</p><p>For model predictions, we designed 6 simulated environments to represent each task using the MDP formalism. The formalized tasks are shown in Figure <ref type="figure" target="#fig_3">3</ref> (experiment 1) and Figure <ref type="figure" target="#fig_6">5 (experiment 2</ref>). An RL agent was trained via tabular Q-learning to converge on an optimal policy separately for each task. From the converged models, we computed four appraisal measures using the equations of the previous section. The resulting appraisal vectors were classifed into modal emotion probabilities using an SVM, which was calibrated as described in section 3.3. An overview of the data processing fow is shown in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiment 1</head><p>The frst experiment aimed to elicit three emotions in three betweensubjects tasks: happiness, boredom and irritation. The participants carried out tasks that manipulated these target emotions based on appraisal theory. Table <ref type="table" target="#tab_0">1</ref> shows the appraisal profle.</p><p>The MDPs that formalize the three tasks are illustrated in Fig. <ref type="figure" target="#fig_3">3</ref>. For the MDP of the happiness task, serves as the Goal state with positive rewards, while denotes the error state with negative rewards. Initiating from the state , the agent can perform the exclusive action , transitioning to 1. This action represents the task's start, and 1 represents the state where the participant is shown a question with two options. These choices are represented by two actions: 1 for the selection that is correct, and 2 for incorrect. Electing for 1 ofers an 80% likelihood for the agent to land in the goal state, contrasted with a 20% chance of ending up in the error state. This probabilistic outcome recognizes the real-world scenario where, despite intending to choose correctly, participants might inadvertently err due to incorrect knowledge or confusion. The appraisal analysis occurs at the onset of the goal state, when the agent transitions from S1 to G. The numerical patterns for  appraisal of the experiment, generated by these models, are shown in Table <ref type="table" target="#tab_1">3</ref>. Note the discrepancy in goal relevance of irritation between Tables <ref type="table" target="#tab_0">1</ref> and<ref type="table" target="#tab_1">3</ref>. The reason for this is that in the experiment, we wanted to emphasize the irritation in human participants by making the obstructing task very goal-relevant.</p><p>The boredom MDP shares a similar confguration in its initial states and 1. The distinction lies in the reward values:</p><formula xml:id="formula_11">( 1 , 1 , 2 ) is set to 1, while ( 1 , 2 , 2</formula><p>) is set to -1. This design choice makes the task less rewarding, both positively and negatively, implying that the outcome is less important. Appraisal analysis is conducted at 2. In the irritation task, we introduce a high likelihood of reaching the problematic state of the system even when opting for the correct choice 1. This represents the frustrating event when a certainly correct action results in an unwanted state due to system errors. The appraisal analysis happens accordingly when the problem state is encountered. The average standardized self-rated emotions from the participants after the tasks and the model predictions are presented in Fig. <ref type="figure" target="#fig_4">4</ref>. Overall, our model achieved a reasonable degree of ft to  the data, 2 = 0.78, RMSE = 0.13. The manipulations proved effective for both human evaluations and model outcomes. In every task, both humans and the model rated the target emotion with the highest intensity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experiment 2</head><p>Our second experiment aimed to expose the process nature of emotion and show that a static snapshot emotional state, either via a self-report or a model-based prediction, does not provide a full understanding of emotions during the interaction. To that end, the participants again interacted with the tasks designed to elicit one of the three emotions, but now they self-reported their emotions four times: beginning, twice during the tasks, and at the end of the experiment. While these separate self-reports are still static measurements alone, the progression of these self-reports over time can be used to evaluate the process nature of emotion and how well our model captures that. Figure <ref type="figure" target="#fig_6">5</ref> illustrates the MDPs utilized in the second experiment. They bear a resemblance to those from the frst experiment, but are extended to three appraisal stages. Unlike the participants, who were expected to already have some emotional experiences upon  starting the experiment, our model does not have the frst emotion measurement. That complicates how the SMA (Eq. 9) is implemented. Thus, the initial emotions of the model were set to the average initial values obtained from human participants when they rated their emotions before the task started. At each time stage, we extracted appraisals from the model. Using the same trained SVM classifer as in the frst experiment, these appraisals were then transformed into predictions of modal emotion intensities. We did not recalibrate the SVM classifer's parameters for this new experiment. Unlike in the frst experiment, we used the average of the current and previous emotion predictions to capture the process nature of emotion.</p><p>We performed a regression analysis on the human emotion values against our model's predictions, with each experiment as a fxed term. The results yielded an 2 = 0.86, RMSE of 0.19, a reasonable ft between predictions and responses. From Figure <ref type="figure" target="#fig_7">6</ref>, it is evident that the targeted emotions increase over time, while the non-targeted ones decrease. This trend is consistent in both human evaluations and model predictions, and is particularly pronounced in the happiness and irritation tasks.</p><p>However, the results from the boredom task warrant further discussion. The boredom rating sees an uptick, but there's also a slight increase in participants' irritation ratings. This can be attributed to the inherent challenge in designing a universally neutral interactive task. In our boredom task, the repetitiveness of the simple questions, combined with the sheer volume and limited feedback, likely led to participants becoming impatient and consequently irritated. Furthermore, the self-reported happiness levels in the boredom task were higher than boredom ratings, potentially due to participant response bias where the participants want to provide good feedback to the experimenters and are generally favorable of their task designs <ref type="bibr" target="#b48">[49]</ref>. This might have resulted in over-reporting happiness in a task designed primarily to elicit boredom. This is also possible for the happiness task in the frst experiment, where the participants did not report as much boredom as predicted by the model. However, a more general view of all the graphs over these time stages clearly shows a decline in happiness and a rise in boredom. This points to the need for a more in-depth data analysis, focusing on the temporal shifts in emotion ratings as a contextual reference for participants' emotional responses. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION AND CONCLUSION</head><p>Empirical evaluation: The goal of the paper was to adapt and demonstrate a computational cognitive emotion model that simulates emotion in response to goal-driven interaction events. With some exceptions, the model closely mirrored emotional self-reports collected from human participants engaging in interactive tasks. This accuracy stemmed from incorporating appraisal theory into an RL computational framework, facilitated by a theory linking reward prediction errors with emotional responses <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b53">54]</ref>. Furthermore, our fndings support the validity of appraisal theory, as both the human and computational experiment task designs were rooted in appraisal-centric hypotheses.</p><p>While our validating experiments included human participants self-reporting their emotions, future research should extend its scope into more emotions and tasks. The designed interventions intentionally exerted a pronounced emotional impact, and the tasks do not represent the wide range of tasks typically performed by humans on computers. In the future, adapting the model for more involved interactive scenarios beyond the simple interactions discussed here is crucial. The MDP framework utilized in this paper has simulated various interactions, such as multitasking while driving <ref type="bibr" target="#b16">[17]</ref>, touchscreen typing <ref type="bibr" target="#b15">[16]</ref>, and GUI-based decision-making <ref type="bibr" target="#b7">[8]</ref>. Given that these tasks elicit emotions, our model should be able to predict them. Furthermore, while happiness, boredom, and irritation are prevalent emotions in interaction, there are other emotions relevant in HCI. We limited the amount of emotion to these key ones to focus on testing the model. However, there is a broader spectrum of emotions that the model should be able to predict. The challenge for future research lies in either controlling the experiments carefully to elicit targeted emotions, or collecting a large naturalistic dataset that considers a wide range of lived human emotions. Finally, this paper used a simple moving window average to capture the persistence of emotion throughout an episode. In the future, more complicated formulas should be considered and the complex time-dependent dynamic of emotion investigated.</p><p>Implications: In the future, we foresee our model used in interactive systems that anticipate and adapt to their users' states <ref type="bibr" target="#b13">[14]</ref>, including emotional responses. Even in its current theoretical form, the model can provide designers with insights by allowing them to examine how variations in task progression or user goals infuence emotional outcomes. This implies that the model discussed herein should be adjustable individually, and tailored to a specifc user's objectives and profciency. By inferring a user's underlying cognitive states, the model's alignment with the human user can be enhanced, potentially boosting the accuracy and validity of its predictions.</p><p>Conclusion: With the increase in automated and intelligent machines that interact with their users, it becomes imperative that collaborative agents possess an understanding of their human users. A crucial aspect of this understanding is emotion. Alignment between humans and technologies embedded with artifcial intelligence is risked, if the latter cannot predict their users' emotional responses to interactive events. With computational cognitive models like those developed here, it becomes possible to implement an explicit understanding of emotion into artifcial agents. This understanding is not merely an ability to predict, given observed behavior or physiological signals, but to provide reasons for the causes of predicted emotions and internally simulate various 'what if' experiments to facilitate fuent interaction with the user. For the purposes of open science as recommended by <ref type="bibr" target="#b51">[52]</ref> we present the model code and data from the experiments freely available at <ref type="url" target="https://gitlab.jyu.f/zhangjy/simulating_emotions_chi">https://gitlab.jyu.f/zhangjy/simulating_emotions_chi</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A DATA PROCESSING FLOW</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B EXPERIMENTAL SETUP (EXPERIMENTS 1 AND 2)</head><p>The text used in the tasks (from <ref type="url" target="https://en.wikipedia.org/wiki/English_language">https://en.wikipedia.org/wiki/ English_language</ref>) Modern English has spread around the world since the 17th century as a consequence of the worldwide infuence of the British Empire and the United States of America. Through all types of printed and electronic media of these countries, English has become the leading language of international discourse and the lingua franca in many regions and professional contexts such as science, navigation and law. English is the most spoken language in the world and the third-most spoken native language in the world, after Standard Chinese and Spanish. It is the most widely learned second language and is either the ofcial language or one of the ofcial languages in 59 sovereign states. There are more people who have learned English as a second language than there are native speakers. As of 2005, it was estimated that there were over 2 billion speakers of English. English is the majority native language in the United Kingdom, the United States, Canada, Australia, New Zealand and the Republic of Ireland, and is widely spoken in some areas of the Caribbean, Africa, South Asia, Southeast Asia, and Oceania. It is a co-ofcial language of the United Nations, the European Union and many other world and regional international organisations. It is the most widely spoken Germanic language, accounting for at least 70% of speakers of this Indo-European branch. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Questions for the</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Table 2 :</head><label>2</label><figDesc>Mapping of nominal appraisal values to scales was done by setting the parameters of a normal (N ) or a uniform (U) distribution to correspond to the text description. obstruct N, ≥ 0, = 0, = 0.05 very low N, ≥ 0, = 0, = 0.05 low N, ≥ 0, = 0, = 0.1 medium N, = 0, = 0.05 high N, ≤ 1, = 1, = 0.1 open U(0, 1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>4. 1 . 2 Figure 2 :</head><label>122</label><figDesc>Figure 2: Screenshots from the experiments that targeted one of the three emotions. The happiness task was designed to be encouraging and rewarding, the boredom task contained a large number of repetitive tasks and neutral feedback, and the irritation task was ridden with errors and ended up failing the task.</figDesc><graphic coords="5,344.77,381.93,186.63,132.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a) The MDP model for Happiness (b) The MDP model for Boredom (c) The MDP model for Irritation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: MDP models for various emotions. Circles are states and arrows are transitions caused by actions. Denoted are also transition probabilities and rewards, when relevant. In the Happiness model, selecting action 'a1' from state 'S1' results in a 20% probability of encountering an error 'E', mirroring the anticipated error rate among participants. Conversely, in the Irritation model, choosing 'a1' at 'S1' leads to error 'E' with an 80% likelihood, refecting the high probability of system errors occurring during the task.</figDesc><graphic coords="6,359.90,268.51,156.36,68.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: A comparison of human and modeling predictions for emotional ratings in each tasks. Error bars indicate 95% confdence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(a) The MDP model for Happiness in series (b) The MDP model for Boredom in series (c) The MDP model for Irritation in series</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: MDP models in series. Circles are states and arrows are transitions caused by actions. Denoted are also transition probabilities and rewards, when relevant. The error rates in the Irritation model escalate from 60% to 70%, and fnally to 80%, refecting the true the task failure rates.</figDesc><graphic coords="7,53.80,170.21,240.25,240.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: A comparison of human and model predictions for emotional ratings in each task at each time stage. Targeted emotion magnitudes are reported with numbers.</figDesc><graphic coords="8,53.80,220.75,240.24,195.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: A reinforcement learning agent is trained in a Markov Decision Process-based task environment. Learning signals (TD errors from the converged model) are converted into appraisal predictions, which are classifed into modal emotion predictions using a pre-trained SVM. The classifer is fne-tuned to have human-like spread between emotion ratings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Appraisal patterns for selected emotions and appraisals. Goal rel. = goal relevance, Conduc = conduciveness, obs. = obstruct.</figDesc><table><row><cell></cell><cell cols="4">Suddenness Goal rel. Conduc. Power</cell></row><row><cell cols="2">Happiness low</cell><cell cols="2">medium high</cell><cell>open</cell></row><row><cell>Boredom</cell><cell>very low</cell><cell>low</cell><cell>open</cell><cell>medium</cell></row><row><cell>Irritation</cell><cell>low</cell><cell cols="2">medium obs.</cell><cell>medium</cell></row><row><cell cols="5">analyzed human precision in emotion identifcation from the frst</cell></row><row><cell cols="5">experiment reported below (mean: 0.626, variance: 0.048) and used</cell></row><row><cell cols="2">it as a benchmark.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 :</head><label>3</label><figDesc>Appraisal profles generated by our model.</figDesc><table><row><cell></cell><cell cols="4">Suddenness Goal rel. Conduc. Power</cell></row><row><cell>Happiness</cell><cell>0.2</cell><cell>0.6</cell><cell>0.8</cell><cell>0.87</cell></row><row><cell>Boredom</cell><cell>0</cell><cell>0</cell><cell>0.5</cell><cell>0.53</cell></row><row><cell>Irritation</cell><cell>0.2</cell><cell>1</cell><cell>0</cell><cell>0.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>How did English become the world's leading language? a. Through word of mouth of the British Empire and the US. b. Through printed and electronic media of the British Empire and the US. In which professional contexts is English the leading language? a. Art, music, and sports. b. Science, navigation, and law. Question 19: Which of the following countries has English as a majority native language? a. The Republic of Ireland. b. The Republic of Congo. Question 20: How many sovereign states have English as an ofcial Questions for the Boredom task: Question 1: When has Modern English spread around the world? a. 17th century. b. 18th century. Question 2: Which of the following countries infuenced the spread of modern English? a. The Great Britain. b. France. Question 3: How did English become the world's leading language? a. Through word of mouth of the British Empire and the US. b. Through printed and electronic media of the British Empire and the US. Question 4: Is English the most spoken language in the world? a. Yes, it is. b. No, it isn't. Question 5: Is English the most spoken native language in the world? a. Yes, it is. b. No, it isn't. Question 6: What is the most spoken native language in the world? a. English. b. Chinese. Question 7: What is the most learned second language in the world? a. English. b. Spanish. Question 8: Which of the following categories has a larger number? a. People who speak English as a native language. b. People who learn English as a second language. Question 9: How many people speak English as of 2005? a. 2 billion. b. 3 billion. Question 10: Which of the following countries has English as a majority native language? a. India. b. New Zealand. Question 11: Which of the following languages belongs to the ofcial languages of the United Nations? Which of the following countries infuenced the spread of modern English? a. Australia. b. The United States of America. Question 16: Which of the following statements about English is true? a. It is the most spoken native language. b. It is the most learned second language. Question 17: Which of the following statements about English is true? a. It is the ofcial language in many professions. b. It is a leading language of international discourse. Question 18: When has Modern English spread around the world? a. 16th century. b. 17th century. Question 19: Which of the following countries has English as a majority native language? a. The Republic of Ireland. b. The Republic of Congo. Question 20: How many sovereign states have English as an ofcial language? a. 39. b. 59. Question 21: How did English become the world's leading language? a. Through word of mouth of the British Empire and the US. b. Through printed and electronic media of the British Empire and the US. Question 22: Is English a co-ofcial language of the United Nations? a. Yes, it is. b. No, it isn't. Question 23: Is English the most spoken Germanic language? a. Yes, it is. b. No, it isn't. Question 24: Does English have the most speakers? a. Yes, it does. b. No, it doesn't. Question 25: Does the US infuence the spread of modern English? a. Yes, it does. b. No, it doesn't. Question 26: Is English widely used in many professions? a. Yes, it is. b. No, it isn't. Question 27: Is English the native language in Australia? a. Yes, it is. b. No, it isn't. Question 28: Is English widely spoken in South America? a. Yes, it is. b. No, it isn't. Question 29: Is English a Latin language? a. Yes, it is. b. No, it isn't. Question 30: Which type of language does English belong to? a. Germanic language.</figDesc><table><row><cell>b. France. a. 70%.</cell></row><row><cell>b. 80%. Question 3: Question 4: Is English the most spoken language in the world? Question 15:</cell></row><row><cell>Happiness and Irritation task: Question 1: When has Modern English spread around the world? a. 17th century. b. 18th century. Question 2: Which of the following countries infuenced the spread a. 39. b. 59. a. English. b. Hindi. Question 12: What type of language is English? a. Germanic language. b. Latin language. Question 13: What is the most spoken Germanic language? a. German. Question 18: language? a. Yes, it is. b. No, it isn't. Question 5: Is English the most spoken native language in the world? a. Yes, it is. b. No, it isn't. Question 6: What is the most spoken native language in the world? a. English. b. Chinese. Question 7: What is the most learned second language in the world? a. English. b. Spanish. Question 8: Which of the following categories has a larger number? a. People who speak English as a native language. b. People who learn English as a second language. Question 9: How many people speak English as of 2005? a. 2 billion. b. 3 billion. Question 10: Which of the following countries has English as a majority native language? a. India. b. New Zealand. Question 11: Which of the following languages belongs to the ofcial languages of the United Nations? a. English. b. Hindi. Question 12: What type of language is English? a. Germanic language. b. Latin language. Question 13: What is the most spoken Germanic language? a. German. b. English. Question 14: What percentage of Germanic speakers are English speakers? a. 70%. b. 80%. Question 15: Which of the following countries infuenced the spread of modern English? a. Australia. b. The United States of America. Question 16: Are there more people who have learned English as a second language than native speakers? a. Yes. b. No. Question 17: Which of the following organizations recognizes Eng-lish as a co-ofcial language? a. African Union. b. European Union. b. English.</cell></row><row><cell>of modern English? Question 14: What percentage of Germanic speakers are English</cell></row><row><cell>a. The Great Britain. speakers?</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This research has been supported by the <rs type="funder">Academy of Finland</rs> (grant <rs type="grantNumber">330347</rs>) and partially sponsored by the <rs type="funder">Hybrid Intelligence project</rs> (grant number <rs type="grantNumber">024.004.022</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ewgsSVw">
					<idno type="grant-number">330347</idno>
				</org>
				<org type="funding" xml:id="_sAYPJs2">
					<idno type="grant-number">024.004.022</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>b. Latin language. Question 31: Which of the following languages belongs to the ofcial languages of the United Nations? a. Swedish. b. English. Question 32: What is the most spoken native language in the world? a. Chinese. b. English. Question 33: What is the most spoken Germanic language? a. German. b. English. Question 34: Which of the following area is English widely spoken?</p><p>a. South America. b. South Asia.</p><p>The questionnaire at the end of experiment  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Afective-cognitive learning and decision making: A motivational reward framework for afective agents</title>
		<author>
			<persName><forename type="first">Hyungil</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosalind</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ternational conference on afective computing and intelligent interaction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="866" to="873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Emotional expressions reconsidered: Challenges to inferring emotion from human facial movements</title>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barrett</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ralph</forename><surname>Adolphs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stacy</forename><surname>Marsella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleix</forename><forename type="middle">M</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><forename type="middle">D</forename><surname>Pollak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological science in the public interest</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="68" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The role of afect and emotion in HCI. Afect and emotion in human-computer interaction: From theory to applications</title>
		<author>
			<persName><forename type="first">Russell</forename><surname>Beale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Peter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">WASABI: Afect simulation for agents with believable interactivity</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Becker-Asano</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>IOS Press</publisher>
			<biblScope unit="volume">319</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">MITHOS-Mixed Reality Interactive Teacher Training System for Confict Situations at School</title>
		<author>
			<persName><forename type="first">Chirag</forename><surname>Bhuvaneshwara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Anglet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Hilpert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lara</forename><surname>Chehayeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ann-Kristin</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daksitha</forename><surname>Withanage Don</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitra</forename><surname>Tsovaltzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Gebhard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antje</forename><surname>Biermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sinah</forename><surname>Auchtor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Society of the Learning Sciences</title>
		<meeting>the International Society of the Learning Sciences</meeting>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bandit models of human behavior: Reward processing in mental disorders</title>
		<author>
			<persName><forename type="first">Djallel</forename><surname>Bounefouf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irina</forename><surname>Rish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillermo</forename><forename type="middle">A</forename><surname>Cecchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artifcial General Intelligence: 10th International Conference, AGI 2017</title>
		<title level="s">Proceedings 10</title>
		<meeting><address><addrLine>Melbourne, VIC, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017-08-15">2017. August 15-18, 2017</date>
			<biblScope unit="page" from="237" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Emotion. The Handbook on Socially Interactive Agents: 20 Years of Research on Embodied Conversational Agents, Intelligent Virtual Agents, and Social Robotics</title>
		<author>
			<persName><forename type="first">Joost</forename><surname>Broekens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods, Behavior, Cognition</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="349" to="384" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A cognitive model of how people make decisions through interaction with visual displays</title>
		<author>
			<persName><forename type="first">Xiuli</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandra</forename><forename type="middle">Dorothee</forename><surname>Starke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Baber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Howes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 CHI conference on human factors in computing systems</title>
		<meeting>the 2017 CHI conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1205" to="1216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Comparative Study on Reward Models for UI Adaptation with Reinforcement Learning</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gaspar-Figueiredo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><surname>Fernández-Diego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvia</forename><surname>Abrahao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emilio</forename><surname>Insfran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">methods</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ALMA: a layered model of afect</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Gebhard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth international joint conference on Autonomous agents and multiagent systems</title>
		<meeting>the fourth international joint conference on Autonomous agents and multiagent systems</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="29" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">20 years of Research on Embodied Conversational Agents</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Gebhard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitra</forename><surname>Tsovaltzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanja</forename><surname>Schneeberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabrizio</forename><surname>Nunnari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interactivity, Platforms</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="527" to="546" />
		</imprint>
	</monogr>
	<note>The Handbook on Socially Interactive Agents</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Evaluating a computational model of emotion</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Gratch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stacy</forename><surname>Marsella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Autonomous Agents and Multi-Agent Systems</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="23" to="43" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Employing Virtual Agents for Building Trust in Driving Automation: A Qualitative Pilot Study</title>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Hilpert</surname></persName>
		</author>
		<author>
			<persName><surname>Gebhard</surname></persName>
		</author>
		<author>
			<persName><surname>Schneeberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Robo-Identity: Artifcial identity and multi embodiment at the 16th International Conference on Human-Robot Interaction (HRI&apos;21)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Towards machines that understand people</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Howes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jussi</forename><surname>Pp Jokinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antti</forename><surname>Oulasvirta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Basic emotions, natural kinds, emotion schemas, and a new paradigm</title>
		<author>
			<persName><surname>Carroll E Izard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perspectives on psychological science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="260" to="280" />
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Touchscreen Typing As Optimal Supervisory Control</title>
		<author>
			<persName><forename type="first">Jussi</forename><surname>Jokinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Uzair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinhui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antti</forename><surname>Oulasvirta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multitasking in driving as optimal adaptation under uncertainty</title>
		<author>
			<persName><forename type="first">Tuomo</forename><surname>Jussi Pp Jokinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antti</forename><surname>Kujala</surname></persName>
		</author>
		<author>
			<persName><surname>Oulasvirta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human factors</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1324" to="1341" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Autonomic nervous system activity in emotion: A review</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sylvia</surname></persName>
		</author>
		<author>
			<persName><surname>Kreibig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological psychology</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="394" to="421" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Psychophysiological response patterning in emotion: Implications for afective computing. A blueprint for an afectively competent agent: Cross-fertilization between emotion psychology</title>
		<author>
			<persName><forename type="first">Gunnar</forename><surname>Sylvia D Kreibig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Schaefer</surname></persName>
		</author>
		<author>
			<persName><surname>Brosch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">afective neuroscience, and afective computing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="105" to="130" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Workplace user frustration with computers: An exploratory investigation of the causes and severity</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Lazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behaviour &amp; Information Technology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="239" to="251" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Exploring the relationship between smartphone activities, fow experience, and boredom in free time</title>
		<author>
			<persName><forename type="first">Louis</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="130" to="139" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Computational rationality: Linking mechanism and behavior through bounded utility maximization</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Richard L Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satinder</forename><surname>Howes</surname></persName>
		</author>
		<author>
			<persName><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in cognitive science</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="279" to="311" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The Handbook on Socially Interactive Agents: 20 years of Research on Embodied Conversational Agents</title>
		<author>
			<persName><forename type="first">Birgit</forename><surname>Lugrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Pelachaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Traum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interactivity, Platforms, Application</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">EMA: A process model of appraisal dynamics</title>
		<author>
			<persName><forename type="first">C</forename><surname>Stacy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Marsella</surname></persName>
		</author>
		<author>
			<persName><surname>Gratch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Systems Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="70" to="90" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The phenomenon of boredom</title>
		<author>
			<persName><forename type="first">Marion</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaynor</forename><surname>Sadlo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Stew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Qualitative Research in Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="193" to="211" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Momentary pleasure or lasting meaning? Distinguishing eudaimonic and hedonic user experiences</title>
		<author>
			<persName><forename type="first">D</forename><surname>Elisa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kasper</forename><surname>Mekler</surname></persName>
		</author>
		<author>
			<persName><surname>Hornbaek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 chi conference on human factors in computing systems</title>
		<meeting>the 2016 chi conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4509" to="4520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Nonlinear appraisal modeling: An application of machine learning to the study of emotion production</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Meuleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Afective Computing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="398" to="411" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Emotion in reinforcement learning agents and robots: a survey</title>
		<author>
			<persName><forename type="first">Joost</forename><surname>Thomas M Moerland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catholijn</forename><forename type="middle">M</forename><surname>Broekens</surname></persName>
		</author>
		<author>
			<persName><surname>Jonker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="443" to="480" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Appraisal theories of emotion: State of the art and future development</title>
		<author>
			<persName><forename type="first">Agnes</forename><surname>Moors</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phoebe</forename><forename type="middle">C</forename><surname>Ellsworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nico</forename><forename type="middle">H</forename><surname>Frijda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Emotion Review</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="119" to="124" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Advocating a componential appraisal model to guide emotion recognition</title>
		<author>
			<persName><forename type="first">Marcello</forename><surname>Mortillaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Meuleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Synthetic Emotions (IJSE)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="18" to="32" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ortony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerald</forename><forename type="middle">L</forename><surname>Clore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allan</forename><surname>Collins</surname></persName>
		</author>
		<title level="m">The cognitive structure of emotions</title>
		<imprint>
			<publisher>Cambridge university press</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Computational rationality as a theory of interaction</title>
		<author>
			<persName><forename type="first">Antti</forename><surname>Oulasvirta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Jussi Pp Jokinen</surname></persName>
		</author>
		<author>
			<persName><surname>Howes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2022 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Afective computing</title>
		<author>
			<persName><forename type="first">Rosalind</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Rosalind</forename><forename type="middle">Wright</forename><surname>Picard</surname></persName>
		</author>
		<title level="m">Afective computing</title>
		<imprint>
			<date type="published" when="1995">1995. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Look What I Made It Do-The Mod-elIT Method for Manually Modeling Nonverbal Behavior of Socially Interactive Agents</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Lea Reinwarth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanja</forename><surname>Schneeberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabrizio</forename><surname>Nunnari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Gebhard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uwe</forename><surname>Altmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janet</forename><surname>Wessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GENEA: Generation and Evaluation of Non-verbal Behaviour for Embodied Agents Workshop</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Core afect and the psychological construction of emotion</title>
		<author>
			<persName><forename type="first">Russell</forename><surname>James</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">145</biblScope>
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A systems approach to appraisal mechanisms in emotion</title>
		<author>
			<persName><forename type="first">David</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Didier</forename><surname>Grandjean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="317" to="352" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Formalizing emotion concepts within a Bayesian model of theory of mind</title>
		<author>
			<persName><forename type="first">Rebecca</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Dae Houlihan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current opinion in Psychology</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="15" to="21" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Appraisal considered as a process of multilevel sequential checking</title>
		<author>
			<persName><forename type="first">Klaus</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Appraisal processes in emotion: Theory, methods, research</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="92" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">What are emotions? And how can they be measured</title>
		<author>
			<persName><forename type="first">Klaus</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social science information</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="695" to="729" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The dynamic architecture of emotion: Evidence for the component process model</title>
		<author>
			<persName><forename type="first">Klaus</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition and emotion</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1307" to="1351" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Emotions are emergent processes: they require a dynamic computational architecture</title>
		<author>
			<persName><forename type="first">Klaus</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">364</biblScope>
			<biblScope unit="page" from="3459" to="3474" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Towards a prediction and data driven computational process model of emotion</title>
		<author>
			<persName><forename type="first">Klaus</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Afective Computing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="279" to="292" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Transfer of Social Human-Human Interaction to Social Human-Agent Interaction</title>
		<author>
			<persName><forename type="first">Tanja</forename><surname>Schneeberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems</title>
		<meeting>the 17th International Conference on Autonomous Agents and MultiAgent Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1778" to="1780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The Deep Method: Towards Computational Modeling of the Social Emotion Shame driven by Theory, Introspection, and Social Signals</title>
		<author>
			<persName><forename type="first">Tanja</forename><surname>Schneeberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Hladkỳ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ann-Kristin</forename><surname>Thurner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jana</forename><surname>Volkert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Heimerl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Baur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elisabeth</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Gebhard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Afective Computing</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Can social agents elicit shame as humans do?</title>
		<author>
			<persName><forename type="first">Tanja</forename><surname>Schneeberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Scholtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Hilpert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Langer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Gebhard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 8th International Conference on Afective Computing and Intelligent Interaction (ACII)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="164" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Putting appraisal in context: Toward a relational model of appraisal and emotion</title>
		<author>
			<persName><forename type="first">A</forename><surname>Craig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leslie</forename><forename type="middle">D</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><surname>Kirby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition and Emotion</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1352" to="1372" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
	<note>2nd ed</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">You Can Always Do Better!&quot; The Impact of Social Proof on Participant Response Bias</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Vashistha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabian</forename><surname>Okeke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Dell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 chi conference on human factors in computing systems</title>
		<meeting>the 2018 chi conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The social signal interpretation (SSI) framework: multimodal signal processing and recognition in real-time</title>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Lingenfelser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Baur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ionut</forename><surname>Damian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Kistler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elisabeth</forename><surname>André</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st ACM international conference on Multimedia</title>
		<meeting>the 21st ACM international conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="831" to="834" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A systematic review on affective computing: Emotion models, databases, and recent advances</title>
		<author>
			<persName><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Liotta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinlei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyong</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixuan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weifeng</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="19" to="52" />
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Empirical research in afective computing: an analysis of research practices and recommendations</title>
		<author>
			<persName><forename type="first">Janet</forename><surname>Wessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanja</forename><surname>Schneeberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Hilpert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Alles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Gebhard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 9th International Conference on Afective Computing and Intelligent Interaction (ACII)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A Markov reward process-based framework for resilience analysis of multistate energy systems under the threat of extreme events</title>
		<author>
			<persName><forename type="first">Zhiguo</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi-Ping</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingqing</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shijia</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reliability Engineering &amp; System Safety</title>
		<imprint>
			<biblScope unit="volume">209</biblScope>
			<biblScope unit="page">107443</biblScope>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Modeling Cognitive-Afective Processes with Appraisal and Reinforcement Learning</title>
		<author>
			<persName><forename type="first">Jiayi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joost</forename><surname>Broekens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jussi</forename><surname>Jokinen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.06367[cs</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
